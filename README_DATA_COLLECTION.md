# Sistema de Coleta de Dados - Modelo NetLogo Scapegoat

## üìã Vis√£o Geral

Este documento descreve o sistema de instrumenta√ß√£o de dados do modelo NetLogo Scapegoat, projetado para facilitar a compara√ß√£o com dados emp√≠ricos do Twitter.

## üéØ Arquivos Exportados

### 1. `data/events.csv` - Log de Eventos
**Descri√ß√£o**: Registro detalhado de cada intera√ß√£o/acusa√ß√£o que ocorre no modelo.

**Colunas**:
- `tick`: momento temporal do evento
- `source`: ID do agente acusador
- `target`: ID do agente acusado
- `etype`: tipo de evento
  - `accuse`: acusa√ß√£o bem-sucedida (v√≠tima criada)
  - `faccuse`: acusa√ß√£o falhada
  - `ritual_accuse`: acusa√ß√£o ritual (l√≠der ‚Üí v√≠tima existente)
  - `ritual_accuse_existing`: ritual sobre v√≠tima pr√©-existente
- `source_kind`: categoria do acusador (`leader`, `neutral`, `accuser_failed`, etc.)
- `target_kind`: categoria da v√≠tima
- `weight`: peso do evento (sempre 1)

**Atualiza√ß√£o**: Cada evento √© registrado no momento exato em que ocorre.

### 2. `data/timeseries.csv` - S√©ries Temporais Globais
**Descri√ß√£o**: M√©tricas agregadas do sistema a cada tick.

**Colunas**:
- `tick`: momento temporal
- `n_alive`: n√∫mero de agentes vivos
- `n_leaders`: n√∫mero de l√≠deres (shape = "square")
- `n_victims`: n√∫mero de v√≠timas (shape = "star")
- `pct_victims`: percentual de v√≠timas
- M√©tricas de sa√∫de: `avggeneralhealth`, `avgleaderhealth`, `avgvictimhealth`
- M√©tricas de grau: `avggenerallinkneighbors`, `avgvictimlinkneighbors`, `avgleaderlinkneighbors`
- M√©tricas de clustering: `avggeneralcc`, `avgleadercc`, `avgvictimcc`
- `pollution`: n√≠vel de polui√ß√£o (0-3)
- `timetoritual`: ticks at√© o pr√≥ximo ritual
- `ritualtime`: dura√ß√£o do ritual atual

**Atualiza√ß√£o**: Uma linha adicionada ao final de cada tick.

### 3. `data/nodes.csv` - Snapshot de N√≥s
**Descri√ß√£o**: Estado atual de todos os agentes no momento da exporta√ß√£o.

**Colunas**:
- `id`: ID √∫nico do agente
- `kind`: categoria (`leader`, `victim`, `neutral`, `accuser_failed`, `victim_failed`)
- `health`: sa√∫de atual (0-4)
- `tension`: tens√£o atual (0-3)
- `cc_node`: coeficiente de clustering local
- `degree`: grau do n√≥ (n√∫mero de vizinhos)

**Atualiza√ß√£o**: Sob demanda via bot√£o "Export nodes snapshot".

### 4. `data/links_snapshot.csv` - Snapshot de Arestas
**Descri√ß√£o**: Topologia da rede no momento da exporta√ß√£o.

**Colunas**:
- `source`: ID do n√≥ origem
- `target`: ID do n√≥ destino

**Atualiza√ß√£o**: Sob demanda via bot√£o "Export links snapshot".

## üéÆ Bot√µes da Interface NetLogo

Adicione os seguintes bot√µes na Interface do NetLogo:

### Bot√µes de Inicializa√ß√£o
- **Export events header**: Cria `events.csv` com cabe√ßalho (chame antes de iniciar coleta)
- **Export timeseries header**: Cria `timeseries.csv` com cabe√ßalho (chame antes de iniciar coleta)

### Bot√µes de Snapshot (sob demanda)
- **Export nodes snapshot**: Exporta estado atual dos n√≥s ‚Üí `nodes.csv`
- **Export links snapshot**: Exporta topologia atual ‚Üí `links_snapshot.csv`
- **Export plots (opcional)**: Exporta gr√°ficos ‚Üí `plots.csv`

### Controle de Coleta
- **Toggle data collector**: Liga/desliga `datacollector?` (controla pausas visuais)

**Nota**: Os headers s√£o criados automaticamente no `setup`, mas voc√™ pode recri√°-los manualmente com os bot√µes.

## üöÄ Fluxo de Trabalho

### Passo 1: Prepara√ß√£o (primeira vez)
```bash
# Certifique-se de que a pasta data/ existe
cd c:\Users\Paes1\NETLOGO\scapegoat_pipeline_gephi
```

### Passo 2: Configurar NetLogo
1. Abra `scapegoat_instrumented.nlogo` no NetLogo
2. Configure par√¢metros: `numnodes`, `friendliness`, `skepticism`, `scapegoat?`
3. Clique em **setup** (cria headers automaticamente)

### Passo 3: Rodar Simula√ß√£o
1. Clique em **go** (ou ative go-forever)
2. Os dados s√£o coletados automaticamente:
   - `events.csv` cresce a cada acusa√ß√£o
   - `timeseries.csv` cresce a cada tick
3. Para pausar sem perder dados, pare o **go**

### Passo 4: Exportar Snapshot da Rede (quando quiser)
1. Pause a simula√ß√£o (ou n√£o, se quiser capturar em movimento)
2. Clique em **Export nodes snapshot**
3. Clique em **Export links snapshot**
4. Verifique que `nodes.csv` e `links_snapshot.csv` foram criados

### Passo 5: Gerar GEXF para Gephi
```bash
# No terminal (PowerShell/Bash)
cd c:\Users\Paes1\NETLOGO\scapegoat_pipeline_gephi
python tools/make_gexf.py
```

**Sa√≠da**:
- `data/network.gexf` (formato Gephi)
- `data/network.graphml` (alternativa)

### Passo 6: Importar no Gephi
1. Abra o Gephi
2. File ‚Üí Open ‚Üí `data/network.gexf` ou `data/network.graphml`
3. Escolha "Undirected graph" (se preferir)
4. Os atributos dos n√≥s (`kind`, `health`, `tension`, `cc_node`, `degree`) estar√£o dispon√≠veis no Data Laboratory

## üìä An√°lise de Dados

### Exemplo: Carregar eventos em Python/Pandas
```python
import pandas as pd

# Ler eventos
events = pd.read_csv("data/events.csv")
print(events.head())

# Filtrar apenas acusa√ß√µes bem-sucedidas
accuses = events[events['etype'] == 'accuse']
print(f"Total de acusa√ß√µes: {len(accuses)}")

# Agrupar por tipo de evento
print(events['etype'].value_counts())
```

### Exemplo: Carregar s√©ries temporais
```python
timeseries = pd.read_csv("data/timeseries.csv")

# Plotar evolu√ß√£o de v√≠timas
import matplotlib.pyplot as plt
plt.plot(timeseries['tick'], timeseries['n_victims'])
plt.xlabel('Tick')
plt.ylabel('N√∫mero de V√≠timas')
plt.title('Evolu√ß√£o Temporal de V√≠timas')
plt.show()
```

### Exemplo: Comparar com dados emp√≠ricos
```python
# Carregar dados do Twitter (exemplo usando o script existente)
from scripts.windowed_metrics import load_events, compute_window_metrics

# Carregar eventos simulados
sim_events = pd.read_csv("data/events.csv")

# Carregar eventos emp√≠ricos (exemplo)
emp_events = pd.read_json("notebooks/tweets_classified_monark.jsonl", lines=True)

# Comparar distribui√ß√µes
print("Simulado:", sim_events['etype'].value_counts(normalize=True))
print("Emp√≠rico:", emp_events['type'].value_counts(normalize=True))
```

## üîç Verifica√ß√£o de Integridade

### Crit√©rios de Aceite

1. **`data/events.csv` existe e tem ‚â• 2 linhas** (header + eventos)
   ```bash
   wc -l data/events.csv  # Linux/Mac
   (Get-Content data/events.csv).Length  # PowerShell
   ```

2. **`data/timeseries.csv` cresce a cada tick**
   - N√∫mero de linhas = 1 (header) + n√∫mero de ticks executados

3. **`data/nodes.csv` reflete o tick atual**
   - Conte os n√≥s na View do NetLogo
   - Compare com `wc -l data/nodes.csv - 1` (subtrair header)

4. **`data/network.gexf` abre no Gephi sem erros**
   - Teste de encoding UTF-8
   - Teste de IDs de n√≥s consistentes

## üõ†Ô∏è Resolu√ß√£o de Problemas

### Erro: "pasta data/ n√£o existe"
```powershell
New-Item -ItemType Directory -Force -Path "data"
```

### Erro: "CSV n√£o est√° sendo criado"
- Verifique permiss√µes de escrita na pasta `data/`
- Veja mensagens no Command Center do NetLogo
- Teste manualmente: clique em "Export events header"

### Erro: "make_gexf.py n√£o encontra arquivos"
- Certifique-se de que `nodes.csv` e `links_snapshot.csv` existem
- Rode os bot√µes de snapshot antes de executar o script Python

### Erro: "GEXF n√£o abre no Gephi"
- Verifique se NetworkX est√° instalado: `pip install networkx`
- Tente importar o `network.graphml` alternativo
- Verifique se h√° n√≥s com IDs duplicados

## üìö Refer√™ncias

- **Extens√£o CSV NetLogo**: https://ccl.northwestern.edu/netlogo/docs/csv.html
- **NetworkX GEXF**: https://networkx.org/documentation/stable/reference/readwrite/gexf.html
- **Gephi**: https://gephi.org/

## üìù Notas de Implementa√ß√£o

### Mudan√ßas no C√≥digo Original

1. **Adicionados helpers de logging** (in√≠cio do arquivo):
   - `write-events-header`
   - `write-timeseries-header`
   - `log-event [src-agent tgt-agent etype]`
   - `append-timeseries-row`
   - `export-nodes-snapshot`
   - `export-links-snapshot`

2. **Inser√ß√µes de `log-event` nos pontos de acusa√ß√£o**:
   - Ritual de acusa√ß√£o (l√≠der ‚Üí v√≠tima)
   - Acusa√ß√µes espont√¢neas (agente ‚Üí agente)
   - Acusa√ß√µes falhadas (faccuser ‚Üí faccused)
   - Total: ~15 pontos de inser√ß√£o

3. **Chamadas em `setup`**:
   - `write-events-header`
   - `write-timeseries-header`

4. **Chamadas em `go` (final)**:
   - `append-timeseries-row` (ap√≥s atualizar globais)

5. **Bloco removido**:
   - `file-open "scapegoat.txt"` + `file-print (word ...)` (estava quebrado e conflitava com CSV)

### Preserva√ß√£o da L√≥gica Original

- **Nenhuma** mudan√ßa em condi√ß√µes, probabilidades, `random`, `stop`, etc.
- **Apenas** adi√ß√£o de chamadas `log-event` e `append-timeseries-row`
- **Idempot√™ncia** garantida: executar `setup` m√∫ltiplas vezes recria headers

## üéì Uso Acad√™mico

Este sistema permite:
- **Valida√ß√£o de modelo**: comparar padr√µes simulados com dados reais
- **Calibra√ß√£o de par√¢metros**: ajustar `friendliness`, `skepticism` para match emp√≠rico
- **An√°lise de sensibilidade**: variar par√¢metros e observar impacto em m√©tricas
- **Visualiza√ß√£o din√¢mica**: exportar snapshots em diferentes momentos (pr√©-ritual, p√≥s-ritual, steady-state)

## üìû Suporte

Para d√∫vidas ou problemas, abra uma issue no reposit√≥rio ou entre em contato com os mantenedores do projeto.

---

**Vers√£o**: 1.0  
**Data**: Outubro 2025  
**Licen√ßa**: Ver arquivo LICENSE no reposit√≥rio

