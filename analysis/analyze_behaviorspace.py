#!/usr/bin/env python3
"""
Script para anÃ¡lise de dados do BehaviorSpace do NetLogo
Analisa simulaÃ§Ãµes contra mÃ©tricas empÃ­ricas do caso Karol ConkÃ¡
"""

import pandas as pd
import numpy as np
import glob
import os
from pathlib import Path

# Metas empÃ­ricas do caso Karol ConkÃ¡
TARGETS = {
    "largest_wcc_nodes": 191,
    "degree_assortativity_ud": -0.39,
    "modularity_ud": 0.64,
    "avg_shortest_path_lcc": 3.17,
    "diameter_lcc": 7,
    "avg_clustering_ud": 0.00,
    "n_nodes": 318,
    "n_edges": 304,
}

# TolerÃ¢ncias para mÃ©tricas de tamanho
TOL = {"n_nodes": 0.1, "n_edges": 0.1}  # Â±10% para tamanho

def load_csvs(pattern="data/behaviorspace/*.csv"):
    """
    Carrega e concatena todos os CSVs do BehaviorSpace
    Normaliza nomes de colunas (lowercase, espaÃ§os por _)
    """
    print(f"ðŸ” Buscando arquivos com padrÃ£o: {pattern}")
    
    # Buscar arquivos
    files = glob.glob(pattern)
    if not files:
        print(f"âŒ Nenhum arquivo encontrado com padrÃ£o: {pattern}")
        return pd.DataFrame()
    
    print(f"ðŸ“ Encontrados {len(files)} arquivos:")
    for f in files:
        print(f"  - {f}")
    
    # Carregar e concatenar CSVs
    dfs = []
    for file in files:
        try:
            df = pd.read_csv(file)
            dfs.append(df)
            print(f"âœ… Carregado: {file} ({len(df)} linhas)")
        except Exception as e:
            print(f"âŒ Erro ao carregar {file}: {e}")
    
    if not dfs:
        print("âŒ Nenhum CSV foi carregado com sucesso")
        return pd.DataFrame()
    
    # Concatenar todos os DataFrames
    combined_df = pd.concat(dfs, ignore_index=True)
    print(f"ðŸ“Š Total de linhas combinadas: {len(combined_df)}")
    
    # Normalizar nomes de colunas
    combined_df.columns = combined_df.columns.str.lower().str.replace(' ', '_')
    print(f"ðŸ·ï¸ Colunas normalizadas: {list(combined_df.columns)}")
    
    return combined_df

def score_row(row):
    """
    Calcula score para uma linha baseado nas mÃ©tricas empÃ­ricas
    Retorna dict com erros e score total
    """
    errors = {}
    score = 0.0
    
    for metric, target in TARGETS.items():
        if metric not in row:
            errors[f"err_{metric}"] = np.nan
            continue
        
        value = row[metric]
        if pd.isna(value):
            errors[f"err_{metric}"] = np.nan
            continue
        
        # Calcular erro
        if metric in ["degree_assortativity_ud", "avg_clustering_ud"]:
            # Erro absoluto para essas mÃ©tricas
            error = abs(value - target)
        else:
            # Erro relativo para outras mÃ©tricas
            if target != 0:
                error = abs(value - target) / abs(target)
            else:
                error = abs(value - target)
        
        errors[f"err_{metric}"] = error
        score += error
        
        # Penalidade extra para mÃ©tricas de tamanho se sair do range
        if metric in TOL:
            tolerance = TOL[metric]
            if abs(value - target) / target > tolerance:
                penalty = 2.0  # Penalidade extra
                score += penalty
                errors[f"err_{metric}_penalty"] = penalty
            else:
                errors[f"err_{metric}_penalty"] = 0.0
    
    errors["score_total"] = score
    return errors

def analyze_behaviorspace():
    """
    FunÃ§Ã£o principal de anÃ¡lise
    """
    print("ðŸš€ ANÃLISE DO BEHAVIORSPACE - CASO KAROL CONKÃ")
    print("=" * 60)
    
    # Carregar dados
    df = load_csvs()
    if df.empty:
        print("âŒ NÃ£o foi possÃ­vel carregar dados. Encerrando.")
        return
    
    print(f"\nðŸ“Š Dataset carregado:")
    print(f"  - Linhas: {len(df)}")
    print(f"  - Colunas: {len(df.columns)}")
    
    # Verificar se as mÃ©tricas alvo existem
    missing_metrics = [m for m in TARGETS.keys() if m not in df.columns]
    if missing_metrics:
        print(f"âš ï¸ MÃ©tricas nÃ£o encontradas: {missing_metrics}")
    
    # Calcular erros e scores
    print("\nðŸ§® Calculando erros e scores...")
    
    error_data = []
    for idx, row in df.iterrows():
        errors = score_row(row)
        error_data.append(errors)
    
    # Adicionar colunas de erro ao DataFrame
    error_df = pd.DataFrame(error_data)
    df_with_errors = pd.concat([df, error_df], axis=1)
    
    # Ordenar por score total
    df_with_errors = df_with_errors.sort_values('score_total', ascending=True)
    
    # Criar diretÃ³rio de saÃ­da se nÃ£o existir
    os.makedirs('analysis', exist_ok=True)
    
    # Salvar relatÃ³rio completo
    report_file = 'analysis/bs_report.csv'
    df_with_errors.to_csv(report_file, index=False)
    print(f"ðŸ’¾ RelatÃ³rio completo salvo: {report_file}")
    
    # Criar relatÃ³rio dos top 20
    top_20 = df_with_errors.head(20)
    create_top_report(top_20)
    
    # Mostrar resumo dos 10 melhores
    print_summary(df_with_errors.head(10))
    
    # Mostrar estatÃ­sticas por parÃ¢metro
    print_parameter_stats(df_with_errors)
    
    print(f"\nâœ… AnÃ¡lise concluÃ­da!")
    print(f"ðŸ“ Arquivos gerados:")
    print(f"  - {report_file}")
    print(f"  - analysis/bs_top.md")

def create_top_report(top_df):
    """
    Cria relatÃ³rio Markdown dos top 20 runs
    """
    md_content = "# Top 20 Runs - BehaviorSpace Analysis\n\n"
    md_content += "AnÃ¡lise das melhores simulaÃ§Ãµes contra mÃ©tricas empÃ­ricas do caso Karol ConkÃ¡\n\n"
    
    md_content += "## MÃ©tricas Alvo\n\n"
    for metric, target in TARGETS.items():
        md_content += f"- **{metric}**: {target}\n"
    
    md_content += "\n## Top 20 Runs\n\n"
    md_content += "| Rank | Score | Friendliness | Skepticism | NumNodes | "
    
    # Adicionar colunas para mÃ©tricas principais
    main_metrics = ["largest_wcc_nodes", "degree_assortativity_ud", "modularity_ud", 
                   "avg_shortest_path_lcc", "n_nodes", "n_edges"]
    for metric in main_metrics:
        if metric in top_df.columns:
            md_content += f"{metric} | "
    
    md_content += "\n|------|-------|--------------|------------|----------|"
    for _ in main_metrics:
        md_content += "--------|"
    md_content += "\n"
    
    for idx, (_, row) in enumerate(top_df.iterrows(), 1):
        md_content += f"| {idx} | {row['score_total']:.3f} | "
        
        # ParÃ¢metros principais
        friendliness = row.get('friendliness', 'N/A')
        skepticism = row.get('skepticism', 'N/A')
        numnodes = row.get('numnodes', 'N/A')
        
        md_content += f"{friendliness} | {skepticism} | {numnodes} | "
        
        # MÃ©tricas principais
        for metric in main_metrics:
            if metric in row:
                value = row[metric]
                if pd.isna(value):
                    md_content += "N/A | "
                else:
                    md_content += f"{value:.3f} | "
            else:
                md_content += "N/A | "
        
        md_content += "\n"
    
    # Salvar arquivo
    with open('analysis/bs_top.md', 'w', encoding='utf-8') as f:
        f.write(md_content)
    
    print("ðŸ“„ RelatÃ³rio top 20 salvo: analysis/bs_top.md")

def print_summary(top_10):
    """
    Imprime resumo dos 10 melhores runs
    """
    print("\nðŸ† TOP 10 MELHORES RUNS")
    print("=" * 80)
    
    for idx, (_, row) in enumerate(top_10.iterrows(), 1):
        print(f"\n#{idx} - Score: {row['score_total']:.3f}")
        print(f"  ParÃ¢metros: friendliness={row.get('friendliness', 'N/A')}, "
              f"skepticism={row.get('skepticism', 'N/A')}, "
              f"numnodes={row.get('numnodes', 'N/A')}")
        
        # Mostrar mÃ©tricas principais
        main_metrics = ["largest_wcc_nodes", "degree_assortativity_ud", "modularity_ud", 
                       "avg_shortest_path_lcc", "n_nodes", "n_edges"]
        
        for metric in main_metrics:
            if metric in row and not pd.isna(row[metric]):
                target = TARGETS[metric]
                value = row[metric]
                error = abs(value - target)
                print(f"  {metric}: {value:.3f} (target: {target}, error: {error:.3f})")

def print_parameter_stats(df):
    """
    Imprime estatÃ­sticas por parÃ¢metro
    """
    print("\nðŸ“Š ESTATÃSTICAS POR PARÃ‚METRO")
    print("=" * 60)
    
    # ParÃ¢metros principais para anÃ¡lise
    main_params = ['friendliness', 'skepticism', 'numnodes']
    
    for param in main_params:
        if param in df.columns:
            values = df[param].dropna()
            if len(values) > 0:
                print(f"\n{param.upper()}:")
                print(f"  MÃ©dia: {values.mean():.3f}")
                print(f"  Desvio: {values.std():.3f}")
                print(f"  Min: {values.min():.3f}")
                print(f"  Max: {values.max():.3f}")
                print(f"  Valores Ãºnicos: {values.nunique()}")
    
    # EstatÃ­sticas do score
    scores = df['score_total'].dropna()
    if len(scores) > 0:
        print(f"\nSCORE TOTAL:")
        print(f"  MÃ©dia: {scores.mean():.3f}")
        print(f"  Desvio: {scores.std():.3f}")
        print(f"  Min: {scores.min():.3f}")
        print(f"  Max: {scores.max():.3f}")

if __name__ == "__main__":
    analyze_behaviorspace()
